{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.spatial.distance import cosine as dcos\n",
    "from scipy.io import loadmat\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Flatten, Dropout, Activation, Permute\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "K.set_image_data_format( 'channels_last' )\n",
    "import os\n",
    "from multiprocessing.dummy import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto_crop function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_crop_image(image):\n",
    "    if image is not None:\n",
    "        im = image.copy()\n",
    "        # Load HaarCascade from the file with OpenCV\n",
    "        faceCascade = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "        \n",
    "        # Read the image\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Detect faces in the image\n",
    "        faces = faceCascade.detectMultiScale(\n",
    "            gray,\n",
    "            scaleFactor=1.1,\n",
    "            minNeighbors=5,\n",
    "            minSize=(30, 30)\n",
    "        )\n",
    "        faces = faceCascade.detectMultiScale(gray, 1.2, 5)\n",
    "        if len(faces) > 0:\n",
    "            # Draw a rectangle around the faces\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(image, (x, y), (x+w, y+h), (0, 255, 0), 2)        \n",
    "            (x, y, w, h) = faces[0]\n",
    "            center_x = x+w/2\n",
    "            center_y = y+h/2\n",
    "            height, width, channels = im.shape\n",
    "            b_dim = min(max(w,h)*1.2,width, height)\n",
    "            box = [center_x-b_dim/2, center_y-b_dim/2, center_x+b_dim/2, center_y+b_dim/2]\n",
    "            box = [int(x) for x in box]\n",
    "            # Crop Image\n",
    "            if box[0] >= 0 and box[1] >= 0 and box[2] <= width and box[3] <= height:\n",
    "                crpim = im[box[1]:box[3],box[0]:box[2]]\n",
    "                crpim = cv2.resize(crpim, (224,224), interpolation = cv2.INTER_AREA)\n",
    "                print(\"Found {0} faces!\".format(len(faces)))\n",
    "                return crpim, image, (x, y, w, h)\n",
    "    return None, image, (0,0,0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation de Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convblock(cdim, nb, bits=3):\n",
    "    L = []\n",
    "    for k in range(1,bits+1):\n",
    "        convname = 'conv'+str(nb)+'_'+str(k)\n",
    "        L.append( Convolution2D(cdim, kernel_size=(3, 3), padding='same', activation='relu', name=convname) )\n",
    "    L.append( MaxPooling2D((2, 2), strides=(2, 2)) )\n",
    "    return L\n",
    " \n",
    "def vgg_face_blank():\n",
    "    withDO = True # no effect during evaluation but usefull for fine-tuning\n",
    "    if True:\n",
    "        mdl = Sequential()\n",
    "        mdl.add( Permute((1,2,3), input_shape=(224,224,3)) )\n",
    "        for l in convblock(64, 1, bits=2):\n",
    "            mdl.add(l)\n",
    "        for l in convblock(128, 2, bits=2):\n",
    "            mdl.add(l)        \n",
    "        for l in convblock(256, 3, bits=3):\n",
    "            mdl.add(l)            \n",
    "        for l in convblock(512, 4, bits=3):\n",
    "            mdl.add(l)            \n",
    "        for l in convblock(512, 5, bits=3):\n",
    "            mdl.add(l)        \n",
    "        mdl.add( Convolution2D(4096, kernel_size=(7, 7), activation='relu', name='fc6') )\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        mdl.add( Convolution2D(4096, kernel_size=(1, 1), activation='relu', name='fc7') )\n",
    "        if withDO:\n",
    "            mdl.add( Dropout(0.5) )\n",
    "        mdl.add( Convolution2D(2622, kernel_size=(1, 1), activation='relu', name='fc8') )\n",
    "        mdl.add( Flatten() )\n",
    "        mdl.add( Activation('softmax') )\n",
    "        \n",
    "        return mdl\n",
    "    \n",
    "    else:\n",
    "        raise ValueError('not implemented')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation Des Poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_mat_to_keras(kmodel):\n",
    "    kerasnames = [lr.name for lr in kmodel.layers]\n",
    "    prmt = (0,1,2,3)\n",
    " \n",
    "    for i in range(l.shape[1]):\n",
    "        matname = l[0,i][0,0].name[0]\n",
    "        if matname in kerasnames:\n",
    "            kindex = kerasnames.index(matname)\n",
    "            l_weights = l[0,i][0,0].weights[0,0]\n",
    "            l_bias = l[0,i][0,0].weights[0,1]\n",
    "            f_l_weights = l_weights.transpose(prmt)\n",
    "            assert (f_l_weights.shape == kmodel.layers[kindex].get_weights()[0].shape)\n",
    "            assert (l_bias.shape[1] == 1)\n",
    "            assert (l_bias[:,0].shape == kmodel.layers[kindex].get_weights()[1].shape)\n",
    "            assert (len(kmodel.layers[kindex].get_weights()) == 2)\n",
    "            kmodel.layers[kindex].set_weights([f_l_weights, l_bias[:,0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation du Model CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN model initialization\n",
    "facemodel = vgg_face_blank()\n",
    "# Load the pretrained weights into the model\n",
    "data = loadmat('../Data/vgg-face.mat', matlab_compatible=False, struct_as_record=False)\n",
    "l = data['layers']\n",
    "description = data['meta'][0,0].classes[0,0].description\n",
    " \n",
    "copy_mat_to_keras(facemodel)\n",
    "# Final model that can get inputs and generate a prediction as an output\n",
    "featuremodel = Model( inputs = facemodel.layers[0].input, outputs = facemodel.layers[-2].output )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation de Base de Donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate Database\n",
    "def generate_database(folder_img = \"images\"):\n",
    "    database = {}\n",
    "    for the_file in os.listdir(folder_img):\n",
    "        file_path = os.path.join(folder_img, the_file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "               name = the_file.split(\".\")[0]\n",
    "               img = cv2.imread(file_path)\n",
    "               crpim, srcimg, (x, y, w, h) = auto_crop_image(img)\n",
    "               vector_image = crpim[None,...]\n",
    "               database[name] = featuremodel.predict(vector_image)[0,:]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver le plus proche vecteur dans la base de donnees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(img, database, min_detection=2.5):\n",
    "    imarr1 = np.asarray(img)\n",
    "    imarr1 = imarr1[None,...]\n",
    "    #Prediction\n",
    "    fvec1 = featuremodel.predict(imarr1)[0,:]\n",
    "    #Closest person in DB\n",
    "    dmin = 0.0\n",
    "    umin = \"\"\n",
    "    for key, value in database.items():\n",
    "        fvec2 = value\n",
    "        dcos_1_2 = dcos(fvec1, fvec2)\n",
    "        if umin == \"\":\n",
    "            dmin = dcos_1_2\n",
    "            umin = key\n",
    "        elif dcos_1_2 < dmin:\n",
    "            dmin = dcos_1_2\n",
    "            umin = key\n",
    "    if dmin > min_detection:\n",
    "        umin = \"\"\n",
    "    return umin, dmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lancement de La Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webcam_face_recognizer(database):\n",
    "    cv2.namedWindow(\"preview\")\n",
    "    vc = cv2.VideoCapture(0)\n",
    "    ready_to_detect_identity = True\n",
    "    name = \"\"\n",
    "    \n",
    "    while vc.isOpened():\n",
    "        _, frame = vc.read()\n",
    "        img = frame\n",
    "        # Image analysis (start here with img loaded with your image)\n",
    "        # We do not want to detect a new identity while the program is in the process of identifying another person\n",
    "        imgcrop,img, (x, y, w, h) = auto_crop_image(img)\n",
    "        \n",
    "        if ready_to_detect_identity and imgcrop is not None:\n",
    "            ### Stop analysis while identifying\n",
    "            ready_to_detect_identity = False\n",
    "            pool = Pool(processes=1)\n",
    "            name, ready_to_detect_identity = pool.apply_async(recognize_image, [imgcrop, database]).get()\n",
    "            pool.close()\n",
    "            cv2.putText(img = frame, text = name, org = (int(x),int(y+h+20)), fontFace = cv2.FONT_HERSHEY_SIMPLEX, thickness= 2, fontScale = 1, color = (0, 255, 0))\n",
    "        key = cv2.waitKey(100)\n",
    "        cv2.imshow(\"preview\", img)\n",
    " \n",
    "        if key == 27: # exit on ESC\n",
    "            break\n",
    "    cv2.destroyWindow(\"preview\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
